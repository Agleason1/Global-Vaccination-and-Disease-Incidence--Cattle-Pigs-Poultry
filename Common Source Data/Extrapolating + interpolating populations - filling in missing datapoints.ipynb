{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2735a442",
   "metadata": {},
   "source": [
    "## Kernel to load: vax_inc_general "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3983b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a66c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_imputation_with_fallback_handling(\n",
    "    series, trend='add', seasonal=None, \n",
    "    original_flags=None, original_flag_descriptions=None\n",
    "):\n",
    "    series = series.reset_index(drop=True).copy()  \n",
    "\n",
    "    if series.isnull().all():\n",
    "        raise ValueError(\"The entire series is missing; cannot perform imputation.\")\n",
    "\n",
    "    # Initialize flags and flag descriptions\n",
    "    if original_flags is None:\n",
    "        original_flags = ['O'] * len(series)  # Default flag for \"Original\"\n",
    "    if original_flag_descriptions is None:\n",
    "        original_flag_descriptions = ['Original value'] * len(series)\n",
    "\n",
    "    flags = list(original_flags)\n",
    "    flag_descriptions = list(original_flag_descriptions)\n",
    "\n",
    "    missing_indices = series[series.isnull()].index.tolist()\n",
    "    non_missing_indices = series[series.notnull()].index.tolist()\n",
    "\n",
    "    # If only one non-missing value exists, fill all missing values with it\n",
    "    if len(non_missing_indices) == 1:\n",
    "        single_value = series.iloc[non_missing_indices[0]]\n",
    "        series.fillna(single_value, inplace=True)\n",
    "        for idx in missing_indices:\n",
    "            flags[idx] = 'N'\n",
    "            flag_descriptions[idx] = 'Filled with nearest neighbor (single value available)'\n",
    "        return series, flags, flag_descriptions\n",
    "\n",
    "    #Fill missing values before the first non-missing value\n",
    "    if pd.isnull(series.iloc[0]):\n",
    "        first_valid_index = series.first_valid_index()\n",
    "        nearest_value = series.iloc[first_valid_index]\n",
    "        series.iloc[:first_valid_index] = nearest_value\n",
    "        for idx in range(first_valid_index):\n",
    "            flags[idx] = 'N'\n",
    "            flag_descriptions[idx] = 'Filled with nearest neighbor (start of series)'\n",
    "\n",
    "    # Fill missing values between observed points using linear interpolation\n",
    "    series.interpolate(method='linear', inplace=True)\n",
    "    for idx in missing_indices:\n",
    "        if idx in non_missing_indices:\n",
    "            continue\n",
    "        if idx > non_missing_indices[0] and idx < non_missing_indices[-1]:\n",
    "            flags[idx] = 'L'\n",
    "            flag_descriptions[idx] = 'Filled using linear interpolation'\n",
    "\n",
    "    # Fill missing values after the last observed value using forecasting\n",
    "    for idx in missing_indices:\n",
    "        if idx > non_missing_indices[-1]:\n",
    "            # Use Exponential Smoothing to forecast missing values\n",
    "            try:\n",
    "                model = ExponentialSmoothing(\n",
    "                    series[:idx].dropna().values,\n",
    "                    trend=trend,\n",
    "                    seasonal=seasonal,\n",
    "                    initialization_method=\"heuristic\"\n",
    "                )\n",
    "                fit = model.fit()\n",
    "            except ValueError:\n",
    "                model = ExponentialSmoothing(\n",
    "                    series[:idx].dropna().values,\n",
    "                    trend=trend,\n",
    "                    seasonal=seasonal,\n",
    "                    initialization_method=\"legacy-heuristic\"\n",
    "                )\n",
    "                fit = model.fit()\n",
    "            \n",
    "            forecast = fit.forecast(steps=1)\n",
    "\n",
    "            #Fallback to nearest neighbor or 0 if forecast is negative\n",
    "            if forecast[0] < 0:\n",
    "                last_valid_value = series[:idx].dropna().iloc[-1]  # Last observed value\n",
    "                fallback_value = max(last_valid_value, 0)  # Default to 0 if last valid value is 0\n",
    "                series.iloc[idx] = fallback_value\n",
    "                flags[idx] = 'N'\n",
    "                flag_descriptions[idx] = 'Fallback to nearest neighbor (negative forecast)'\n",
    "            else:\n",
    "                series.iloc[idx] = forecast[0]\n",
    "                flags[idx] = 'I'\n",
    "                flag_descriptions[idx] = 'Imputed using exponential smoothing (forecasted)'\n",
    "\n",
    "    return series, flags, flag_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e916d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in years \n",
    "def add_missing_years(df, start_year=1961, end_year=2024):\n",
    "    earliest_year = df[\"Year\"].min()\n",
    "    latest_year = df[\"Year\"].max()\n",
    "\n",
    "    template_row = df.iloc[0].copy()\n",
    "    static_columns = [\n",
    "        \"Domain Code\", \"Domain\", \"Area Code (M49)\", \"Area\",\n",
    "        \"Element Code\", \"Element\", \"Item Code (CPC)\", \"Item\", \"Unit\",\"ISO3\"\n",
    "    ]\n",
    "    template_row = template_row[static_columns]\n",
    "    \n",
    "    # Create new rows for years before the earliest year\n",
    "    before_years = pd.DataFrame([\n",
    "        {**template_row, \"Year Code\": year, \"Year\": year}\n",
    "        for year in range(start_year, earliest_year)\n",
    "    ])\n",
    "    \n",
    "    # Create new rows for years after the latest year\n",
    "    after_years = pd.DataFrame([\n",
    "        {**template_row, \"Year Code\": year, \"Year\": year}\n",
    "        for year in range(latest_year + 1, end_year + 1)\n",
    "    ])\n",
    "    \n",
    "    other_years_excluded=[year for year in range(earliest_year,latest_year) if year not in df['Year'].tolist()]\n",
    "    during_years = pd.DataFrame([\n",
    "        {**template_row, \"Year Code\": year, \"Year\": year}\n",
    "        for year in other_years_excluded \n",
    "    ])\n",
    "    \n",
    "    df = pd.concat([before_years, df, after_years, during_years], ignore_index=True)\n",
    "\n",
    "    # Add columns to be filled in\n",
    "    df.loc[df['Year'] < earliest_year, 'Value'] = None\n",
    "    df.loc[df['Year'] < earliest_year, 'Flag'] = None\n",
    "    df.loc[df['Year'] < earliest_year, 'Flag Description'] = None\n",
    "    df.loc[df['Year'] < earliest_year, 'Note'] = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12dca203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_gaps_in_years(df):\n",
    "    gaps = []\n",
    "\n",
    "    grouped = df.groupby(['Area', 'Item'])\n",
    "\n",
    "    for (country, item), group in grouped:\n",
    "        group = group.sort_values('Year')\n",
    "\n",
    "        min_year, max_year = group['Year'].min(), group['Year'].max()\n",
    "        all_years = set(range(min_year, max_year + 1))\n",
    "        reported_years = set(group['Year'])\n",
    "\n",
    "        missing_years = all_years - reported_years\n",
    "\n",
    "        if missing_years:\n",
    "            gaps.append({\n",
    "                'Area': country,\n",
    "                'Item': item,\n",
    "                'Min Year': min_year,\n",
    "                'Max Year': max_year,\n",
    "                'Missing Years': sorted(missing_years)\n",
    "            })\n",
    "\n",
    "    gaps_df = pd.DataFrame(gaps)\n",
    "    return gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e4aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accounting for cutoffs for countries (FAO has data from 1960 to 2022)\n",
    "country_existence = {\n",
    "    # Yugoslavia, successors\n",
    "    \"YUG\": {\"start\": 1918, \"end\": 1992}, \n",
    "    \"SCG\": {\"start\": 1992, \"end\": 2006}, \n",
    "\n",
    "    # Soviet Union\n",
    "    \"SUN\": {\"start\": 1922, \"end\": 1991}, \n",
    "\n",
    "    # Germany before reunification\n",
    "    \"DDR\": {\"start\": 1949, \"end\": 1990}, \n",
    "\n",
    "    # Czechoslovakia\n",
    "    \"CSK\": {\"start\": 1918, \"end\": 1992}, \n",
    "\n",
    "    # Zaire\n",
    "    \"ZAR\": {\"start\": 1971, \"end\": 1997}, \n",
    "\n",
    "    # Sudan before splitting\n",
    "    \"SDN-PRE\": {\"start\": 1956, \"end\": 2011},  \n",
    "\n",
    "    # Yemen\n",
    "    \"YMD\": {\"start\": 1967, \"end\": 1990},  \n",
    "    \"YAR\": {\"start\": 1962, \"end\": 1990},  \n",
    "\n",
    "    # Other\n",
    "    \"TPT\": {\"start\": 1976, \"end\": 1999},  \n",
    "    \"NF\": {\"start\": 1901, \"end\": 1980},   \n",
    "    \"RHO\": {\"start\": 1965, \"end\": 1980},  \n",
    "\n",
    "    # Federation of the West Indies\n",
    "    \"WIF\": {\"start\": 1958, \"end\": 1962},  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16062f48",
   "metadata": {},
   "source": [
    "## Exponential smoothing below, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7776315",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapaths=['poultry/original_poultry_pop_2024.csv','poultry/original_killed_poultry_pop_2024.csv',\n",
    "           'poultry/original_pop_egg_layers.csv','cattle/original_cattle_pop_2024.csv',\n",
    "           'cattle/original_killed_cattle_pop_2024.csv','cattle/original_pop_cattle_dairy_cattle.csv',\n",
    "          'swine/original_swine_pop_2024.csv','swine/original_killed_swine_pop_2024.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2b5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_countries_mapping():\n",
    "    \"\"\"\n",
    "    Build and return a dictionary mapping country names to their ISO3 codes.\n",
    "    This includes standard mappings from pycountry and custom overrides.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for country in pycountry.countries:\n",
    "        mapping[country.name] = country.alpha_3\n",
    "\n",
    "    mapping['USA']='USA'\n",
    "    mapping['UK']='GBR'\n",
    "    mapping['Taiwan']='TWN'\n",
    "    mapping['South Korea']='KOR'\n",
    "    mapping['Czech Republic']='CZE'\n",
    "    mapping['Brunei']='BRN'\n",
    "    mapping['Russia']='RUS'\n",
    "    mapping['Iran']='IRN'\n",
    "    mapping['United States of America']='USA'\n",
    "    mapping['Venezuela']='VEN'\n",
    "    mapping['China (Hong Kong SAR)']='HKG'\n",
    "    mapping[\"Cote d'Ivoire\"]='CIV'\n",
    "    mapping['DR Congo']='COD'\n",
    "    mapping['Guinea Bissau']='GNB'\n",
    "    mapping['Lao PDR']='LAO'\n",
    "    mapping['Micronesia (Federated States of)']='FSM'\n",
    "    mapping['North Korea']='PRK'\n",
    "    mapping['Occupied Palestinian Territory']='PSE'\n",
    "    mapping['Swaziland']='SWZ'\n",
    "    mapping['Tanzania']='TZA'\n",
    "    mapping['Bolivia']='BOL'\n",
    "    mapping['Macedonia (TFYR)']='MKD'\n",
    "    mapping['Moldova']='MDA'\n",
    "    mapping['Bolivia (Plurinational State of)']='BOL'\n",
    "    mapping['China, Hong Kong SAR']='HKG'\n",
    "    mapping['China, Taiwan Province of']='TWN'\n",
    "    mapping['China, mainland']='CHN'\n",
    "    mapping['Czechoslovakia']='CSK'\n",
    "    mapping[\"Democratic People's Republic of Korea\"]='PRK'\n",
    "    mapping['Democratic Republic of the Congo']='COD'\n",
    "    mapping['French Guyana']='GUF'\n",
    "    mapping['Micronesia']='FSM'\n",
    "    mapping['Palestine']='PSE'\n",
    "    mapping['Polynesia']='PYF'\n",
    "    mapping['Republic of Korea']='KOR'\n",
    "    mapping['Serbia and Montenegro']='SCG'\n",
    "    mapping['Sudan (former)']='SDN'\n",
    "    mapping['Türkiye']='TUR'\n",
    "    mapping['USSR']='SUN'\n",
    "    mapping['Iran (Islamic Republic of)']='IRN'\n",
    "    mapping['Republic of Moldova']='MDA'\n",
    "    mapping['United Kingdom of Great Britain and Northern Ireland']='GBR'\n",
    "    mapping['United Republic of Tanzania']='TZA'\n",
    "    mapping['Venezuela (Bolivarian Republic of)']='VEN'\n",
    "    mapping['Yugoslav SFR']='YUG'\n",
    "    mapping['Ethiopia PDR']='ETH'\n",
    "    mapping['Central African (Rep.)']='CAF'\n",
    "    mapping[\"China (People's Rep. of)\"]='CHN'\n",
    "    mapping['Chinese Taipei']='TWN'\n",
    "    mapping['Congo (Dem. Rep. of the)']='COD'\n",
    "    mapping['Congo (Rep. of the)']='COG'\n",
    "    mapping[\"Cote D'Ivoire\"]='CIV'\n",
    "    mapping['Dominican (Rep.)']='DOM'\n",
    "    mapping[\"Korea (Dem People's Rep. of)\"]='PRK'\n",
    "    mapping['Korea (Rep. of)']='KOR'\n",
    "    mapping['Laos']='LAO'\n",
    "    mapping['South Sudan (Rep. of)']='SSD'\n",
    "    mapping['Syria']='SYR'\n",
    "    mapping['St. Vincent and the Grenadines']='VCT'\n",
    "    mapping['Vietnam']='VNM'\n",
    "    mapping['Reunion']='REU'\n",
    "    mapping['Guadaloupe']='GLP'\n",
    "    mapping['China, Macao SAR']='MAC'\n",
    "    mapping['Netherlands (Kingdom of the)']='NLD'\n",
    "    mapping['Türkiye (Rep. of)']='TUR'\n",
    "    mapping['Belgium-Luxembourg']='BLX'\n",
    "    mapping['Faeroe Islands']='FRO'\n",
    "    mapping['Cabo verde']='CPV'\n",
    "    mapping['St. Helena']='SHN'\n",
    "    return mapping\n",
    "\n",
    "# Build the mapping once to avoid rebuilding it on every call.\n",
    "COUNTRIES_MAPPING = build_countries_mapping()\n",
    "\n",
    "def get_iso3(country):\n",
    "    \"\"\"\n",
    "    Return the ISO3 code for a given country name.\n",
    "\n",
    "    Args:\n",
    "        country (str): The country name to look up.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The corresponding ISO3 code if found; otherwise, None.\n",
    "    \"\"\"\n",
    "    return COUNTRIES_MAPPING.get(country, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beec1f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing group (BDI, Turkeys): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (CIV, Ducks): The entire series is missing; cannot perform imputation.\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "Error processing group (FSM, Ducks): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (OMN, Ducks): The entire series is missing; cannot perform imputation.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "SUN has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 2\n",
      "*****Finished: poultry/poultry_pop_2024.csv ****\n",
      "Error processing group (CMR, Meat of ducks, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "Error processing group (FSM, Meat of ducks, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (MKD, Meat of ducks, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (MKD, Meat of geese, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (MKD, Meat of turkeys, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (NER, Meat of ducks, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "Error processing group (SRB, Meat of ducks, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (SRB, Meat of geese, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (SRB, Meat of turkeys, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (SSD, Meat of ducks, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "SUN has historical data.\n",
      "Error processing group (SVN, Meat of geese, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (UZB, Meat of turkeys, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "Error processing group (VCT, Meat of turkeys, fresh or chilled): The entire series is missing; cannot perform imputation.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 2\n",
      "*****Finished: poultry/killed_poultry_pop_2024.csv ****\n",
      "CSK has historical data.\n",
      "CSK has historical data.\n",
      "SCG has historical data.\n",
      "SCG has historical data.\n",
      "Error processing group (SSD, Hen eggs in shell, fresh): The entire series is missing; cannot perform imputation.\n",
      "SUN has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 3\n",
      "*****Finished: poultry/pop_egg_layers.csv ****\n",
      "CSK has historical data.\n",
      "SCG has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 2\n",
      "*****Finished: cattle/cattle_pop_2024.csv ****\n",
      "CSK has historical data.\n",
      "SCG has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 2\n",
      "*****Finished: cattle/killed_cattle_pop_2024.csv ****\n",
      "CSK has historical data.\n",
      "SCG has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 2\n",
      "*****Finished: cattle/pop_cattle_dairy_cattle.csv ****\n",
      "CSK has historical data.\n",
      "SCG has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 1\n",
      "*****Finished: swine/swine_pop_2024.csv ****\n",
      "CSK has historical data.\n",
      "SCG has historical data.\n",
      "SUN has historical data.\n",
      "YUG has historical data.\n",
      "# Missing years: 1\n",
      "*****Finished: swine/killed_swine_pop_2024.csv ****\n"
     ]
    }
   ],
   "source": [
    "for datapath in datapaths:\n",
    "    start,end=datapath.split('/')\n",
    "    end=end.replace('original_','')\n",
    "    \n",
    "    data=pd.read_csv(datapath)\n",
    "    data = data[data['Year'] <= 2022] \n",
    "    data.loc[data['Flag'] == 'M', 'Value'] = None  # Set 'Value' to NaN where Flag is 'M' (Missing)\n",
    "    \n",
    "    data['ISO3'] = data['Area'].apply(get_iso3)\n",
    "    if data['ISO3'].isnull().any(): print(\"FIX THIS: Missing ISO3 codes found.\")\n",
    "\n",
    "    \n",
    "    data_frames=[]\n",
    "    \n",
    "    #Process each (ISO3, animal) group separately\n",
    "    for (iso3, animal), group in data.groupby(['ISO3', 'Item']):\n",
    "        # Checking if the ISO3 exists in the historical record\n",
    "        if iso3 in country_existence:\n",
    "            print(f\"{iso3} has historical data.\")\n",
    "    \n",
    "        \n",
    "        # Get the valid year range for the country\n",
    "        if iso3 in country_existence.keys():\n",
    "            valid_start = max(1960, country_existence[iso3]['start'])\n",
    "            valid_end = min(2024, country_existence[iso3]['end'])\n",
    "        else:\n",
    "            valid_start=1960\n",
    "            valid_end=2024\n",
    "        \n",
    "        # Skip processing if the group is empty after filtering\n",
    "        if group.empty:\n",
    "            print(f\"No valid data for {iso3} ({animal}) in the range {valid_start}-{valid_end}.\")\n",
    "            continue\n",
    "        \n",
    "        group = group.sort_values('Year').copy()  \n",
    "        group = add_missing_years(group)  \n",
    "        group = group[(group['Year'] >= valid_start) & (group['Year'] <= valid_end)]\n",
    "    \n",
    "        try:\n",
    "            vals, flags, flag_desc = hybrid_imputation_with_fallback_handling(\n",
    "                group['Value'],\n",
    "                original_flags=group['Flag'],\n",
    "                original_flag_descriptions=group['Flag Description']\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                vals=vals.tolist()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                flags=flags.tolist()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                flag_desc=flag_desc.tolist()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #Assign these results back to the group\n",
    "            group['Value'] = vals\n",
    "            group['Flag'] = flags\n",
    "            group['Flag Description'] = flag_desc\n",
    "            \n",
    "            \n",
    "            data_frames+=[group]\n",
    "    \n",
    "        except Exception as e:  # Catch exceptions for debugging\n",
    "            print(f\"Error processing group ({iso3}, {animal}): {e}\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    full_data=pd.concat(data_frames)\n",
    "    print('# Missing years:',len(find_gaps_in_years(full_data)))\n",
    "    \n",
    "    full_data.to_csv(start+'/'+end,index=False)\n",
    "    \n",
    "    if len(full_data[full_data['Value']<0])>0:\n",
    "        print(\"-------Error: negative prediction. Debug this -------\")\n",
    "    \n",
    "    print('*****Finished:',start+'/'+end,'****')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
